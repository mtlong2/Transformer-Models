{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DisasterDetection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfSkjEG0MAT0"
      },
      "source": [
        "%%capture\n",
        "!wget https://github.com/mtlong2/Datasets/blob/main/disaster_data.zip?raw=true -O disaster_data.zip\n",
        "!unzip disaster_data\n",
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohQIRzn8h_i9"
      },
      "source": [
        "# Disaster text classification using BERT\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig, AdamW\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "import os\n",
        "\n",
        "from tqdm import trange\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6fO5Yzk_iEPN",
        "outputId": "b38909fa-bd10-41c9-eaa0-44884d5f3ffb"
      },
      "source": [
        "model_path = './bert_disaster_detection_state_dict.pth'\n",
        "model_path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./bert_disaster_detection_state_dict.pth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r58oRPrUihlR",
        "outputId": "fb4297e7-1914-42dc-d734-b2f7ffd7f351"
      },
      "source": [
        "text = pd.read_csv('./disaster_data/train.csv').text.values\n",
        "labels = pd.read_csv('./disaster_data/train.csv').target.values\n",
        "print(text.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7613,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "zw-elaGTipCy",
        "outputId": "55f9e534-cae0-4e17-8287-09da9f1f54d3"
      },
      "source": [
        "# plot label distribution\n",
        "plt.hist(labels)\n",
        "plt.xlabel('label')\n",
        "plt.ylabel('label distribution')\n",
        "plt.xticks(np.arange(len(np.unique(labels))))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7fc13f9bf210>,\n",
              "  <matplotlib.axis.XTick at 0x7fc13f9bf1d0>],\n",
              " <a list of 2 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vhb-kXXYj4W1",
        "outputId": "72e588a3-d656-46fc-f945-bbdc61d5237b"
      },
      "source": [
        "# prepare data\n",
        "# Tokenize with BERT Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "padded_seq = tokenizer(list(text), padding=True)\n",
        "print(f\"tokenized inputs {padded_seq['input_ids'][0]}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tokenized inputs [101, 2256, 15616, 2024, 1996, 3114, 1997, 2023, 1001, 8372, 2089, 16455, 9641, 2149, 2035, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJbE29PZj6DV",
        "outputId": "b182107c-1f02-4d67-ae08-7c97dc5a6912"
      },
      "source": [
        "padded_seq.keys()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Jx-lxfj82t"
      },
      "source": [
        "# split data into train and validation sets\n",
        "\n",
        "input_ids = padded_seq['input_ids']\n",
        "attention_masks = padded_seq['attention_mask']\n",
        "\n",
        "train_inputs, val_inputs, train_labels, val_labels = train_test_split(input_ids, labels, random_state=42,\n",
        "                                                                     test_size=0.10)\n",
        "\n",
        "train_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42,\n",
        "                                               test_size=0.10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLmMP3DHj-q1"
      },
      "source": [
        "# convert data into tensors\n",
        "\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "val_labels = torch.tensor(val_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "val_masks = torch.tensor(val_masks)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37XBWs1SkCFM"
      },
      "source": [
        "# create a data interator (generator) for train and validation sets with torch DataLoader\n",
        "batch_size = 16\n",
        "\n",
        "# training generator\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n",
        "\n",
        "# validation generator\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = RandomSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1tpnb_bkJ8E",
        "outputId": "7718143e-913a-44db-9154-515814b51fe3"
      },
      "source": [
        "# load pretrained BERT model\n",
        "# confirm GPU device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "else: print(\"using CPU\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ7NTzJnkMBU",
        "outputId": "6fe0beec-4e2d-4a24-d1ef-4e8e03075b44"
      },
      "source": [
        "# load BertForSequenceClassification (pretrained BERT model with single linear classification layer on top)\n",
        "\n",
        "num_labels = 2\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
        "\n",
        "# push model to GPU, if available\n",
        "model.to(device)\n",
        "\n",
        "# fine-tuning BERT parameters\n",
        "param_optimizer = list(model.named_parameters())\n",
        "\n",
        "no_decay = ['bais','gamma','beta']\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n,p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "               'weight_decay_rate':0.01},\n",
        "    {'params' : [p for n,p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "               'weight_decay_rate':0.0}   \n",
        "]\n",
        "\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7yrAviyk4s0",
        "outputId": "58824daf-7a27-4fa9-f643-9610f2cbd23e"
      },
      "source": [
        "if os.path.exists(model_path):\n",
        "    print (\"Loading weights from saved model...\")\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading weights from saved model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCihR-TFk7zc"
      },
      "source": [
        "# Train Model function\n",
        "\n",
        "def train(model, iterator, optimizer):\n",
        "    model.train()\n",
        "    epoch_loss =0\n",
        "    \n",
        "    for step, batch in enumerate(iterator):\n",
        "        \n",
        "        # input data\n",
        "        batch =tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # reset gradients after every batch\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss = output['loss']\n",
        "        \n",
        "        # backwards pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # take a step using the gradient\n",
        "        optimizer.step()\n",
        "        \n",
        "        #loss\n",
        "        epoch_loss += loss.item()\n",
        "        \n",
        "        if step%100==0:\n",
        "            print(f\"step: {step}\")\n",
        "            \n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdgdddb9k_rP"
      },
      "source": [
        "# Evaluate Model\n",
        "\n",
        "# calculate accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    \n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def evaluate(model, iterator):\n",
        "    # initialize each epoch\n",
        "    epoch_accuracy = 0\n",
        "    \n",
        "    #deactivate dropout layers in evaluate mode\n",
        "    model.eval()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # deactivate autograd in evaluat mode\n",
        "        with torch.no_grad():\n",
        "            # forward pass, calculate logit predictions before passing through accuracy function\n",
        "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "            logits = output['logits']\n",
        "            \n",
        "        # move logits and labels to CPU for processing\n",
        "        # logits = logits.detach().cpu.numpy()\n",
        "        # label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        temp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "       \n",
        "        epoch_accuracy += temp_eval_accuracy\n",
        "        \n",
        "    return epoch_accuracy / len(iterator)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmjYLCSflBz7",
        "outputId": "c7423bce-e1f0-4974-9e28-e44f8017fe34"
      },
      "source": [
        "# train and validate\n",
        "num_epochs  = 2\n",
        "best_val_acc = 0\n",
        "\n",
        "# BERT training loop\n",
        "for _ in trange(num_epochs, desc='Epoch'):\n",
        "    \n",
        "    # train model\n",
        "    train_loss = train(model, train_dataloader, optimizer)\n",
        "    \n",
        "    # evaluate the model\n",
        "    val_accuracy = evaluate(model, val_dataloader)\n",
        "    \n",
        "    # save the best model\n",
        "    if val_accuracy > best_val_acc:\n",
        "        best_val_acc = val_accuracy\n",
        "        print(\"saving model...>..>.\")\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "        \n",
        "    print(f'\\t Training Loss: {train_loss:.3f} | Val. Accuracy: {val_accuracy*100: .2f}%')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/2 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step: 0\n",
            "step: 100\n",
            "step: 200\n",
            "step: 300\n",
            "step: 400\n",
            "saving model...>..>.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 1/2 [02:02<02:02, 122.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Training Loss: 0.439 | Val. Accuracy:  83.52%\n",
            "step: 0\n",
            "step: 100\n",
            "step: 200\n",
            "step: 300\n",
            "step: 400\n",
            "saving model...>..>.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 2/2 [04:03<00:00, 121.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\t Training Loss: 0.320 | Val. Accuracy:  83.57%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOoXr9lklFKr"
      },
      "source": [
        "# make predictions\n",
        "\n",
        "model.to('cpu')\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "def prediction(model, sentence):\n",
        "    encoded_input = tokenizer(sentence, return_tensors=\"pt\")\n",
        "    output = model(**encoded_input)\n",
        "    logits = output.logits\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    \n",
        "    pred = np.argmax(logits, axis=1)[0]\n",
        "    return 'Disaster event' if pred == 1 else 'Not a disaster event'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bAmeeJ9Lxa5K",
        "outputId": "aecc446f-5b95-4fd3-e1df-97416455f6e9"
      },
      "source": [
        "prediction(model, \"Flash flood in Kamdesh provence\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Disaster event'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8dswV_THxfUS",
        "outputId": "c32b7893-2bfc-4734-95fd-b49fac634efc"
      },
      "source": [
        "prediction(model, \"Great weather to go to the beach\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Not a disaster event'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBtOSxtGx3uf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}